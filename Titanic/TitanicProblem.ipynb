{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "TitanicProblem.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS_GZA91HGx2"
      },
      "source": [
        "# Uczenie maszynowe \r\n",
        "\r\n",
        "Titanica Problem\r\n",
        "\r\n",
        "Celem programu jest przedstawienie metod rozwiazywania problemu zwiazanego z uczeniem maszynowym.\r\n",
        "\r\n",
        "W Titanic Problem mamy za zadanie stworzyć model, który potrafi w spósb jak najdokładniejszy określić kto przeżyje w czasie katastrofie statku."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjJ6M0zdAxhV"
      },
      "source": [
        "Pobiranie danych z kaggle, a następnie odczyt danych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "sHN8tXo4Axhg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "fad50bf6-16c0-4d7e-b07d-ad2c3358a75a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "train_data= pd.read_csv(\"/kaggle/input/titanic/train.csv\")\n",
        "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ea6ac3a42505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/titanic/train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/titanic/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/titanic/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWQzFSJPBc9X"
      },
      "source": [
        "titanic_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\r\n",
        "test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\r\n",
        "titanic_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU0V7RghBvHd"
      },
      "source": [
        "titanic_data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxvYnZk5B0P9"
      },
      "source": [
        "titanic_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21tSwz0PDdRs"
      },
      "source": [
        "W tym momęcie brakuej 3 danych takich jak wiek, kabina, zaokrętowanie.\r\n",
        "\r\n",
        "Dane jakie mamy to 5 danych kategori i 5 kolumn (imię i nazwisko, płeć, bilet, kabina, zaokrętowanie).\r\n",
        "\r\n",
        "Dane liczbowe w których mamy 6 kolumn.\r\n",
        "\r\n",
        "Posiadamy 3 określony typy danych liczbowych.\r\n",
        "\r\n",
        "\r\n",
        "-Binary data \r\n",
        "\r\n",
        "\r\n",
        "-Continuous data \r\n",
        "\r\n",
        "\r\n",
        "-Categorical data encoded"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA9BON7kBuSd"
      },
      "source": [
        "print('Survived:', titanic_data.Survived.unique())\r\n",
        "print('Pclass:', titanic_data.Pclass.unique())\r\n",
        "print('SibSp:', titanic_data.SibSp.unique())\r\n",
        "print('Parch:', titanic_data.Parch.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "odNnvxpWAxhk"
      },
      "source": [
        "print('Null Training data %:\\n')\n",
        "\n",
        "print(titanic_data.isnull().mean())\n",
        "\n",
        "print('\\nNull Test data data %:\\n')\n",
        "print(test_data.isnull().mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcfuEqWyEYvF"
      },
      "source": [
        "# W tym miejscu zaczynamy uzupełniać brakujące elementy. Uzuepłniamy dane potrzebne do treningu i do etapu testowania."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ojx8E6PSAxhl",
        "outputId": "3f9174fc-9f3d-4941-84dc-8fd4d34a27a2"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "embarked_mode = titanic_data['Embarked'].mode().values[0]\n",
        "titanic_data['Embarked'].fillna(embarked_mode, inplace=True)\n",
        "\n",
        "\n",
        "titanic_data['Cabin'].fillna('Missing', inplace=True) \n",
        "\n",
        "\n",
        "titanic_data['Age'].fillna(titanic_data['Age'].mean(), inplace=True)\n",
        "\n",
        "\n",
        "test_data['Cabin'].fillna('Missing', inplace=True) \n",
        "\n",
        "\n",
        "test_data['Age'].fillna(test_data['Age'].mean(), inplace=True)\n",
        "\n",
        "\n",
        "test_data['Fare'].fillna(test_data['Fare'].mean(), inplace=True)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filter accuracy: 0.9513513513513514\n",
            "Filter accuracy: 0.9207920792079208\n",
            "Filter accuracy: 0.848314606741573\n",
            "Filter accuracy: 0.9617486338797814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCjMwQeXlkUY"
      },
      "source": [
        "# Rozpoczynamy ustalanie danych kategorii (Imię, płeć, bilet, kabina, zaokrętowany).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YugSHgUlAxhn",
        "outputId": "dc899620-e87d-4080-aea8-3e108a2d377c"
      },
      "source": [
        "print('Sex values:',titanic_data.Sex.unique(), test_data.Sex.unique())\n",
        "print('Ticket values:',titanic_data.Ticket.unique().size,test_data.Ticket.unique().size)\n",
        "print('Cabin values:',titanic_data.Cabin.unique().size,test_data.Cabin.unique().size)\n",
        "print('Embarked values:',titanic_data.Embarked.unique(), test_data.Embarked.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data accuracy: 0.8597081930415263\n",
            "Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuwKXDJPFBmX"
      },
      "source": [
        "temp = pd.get_dummies(titanic_data[['Sex']]) \r\n",
        "titanic_data = titanic_data.join(temp)\r\n",
        "\r\n",
        "temp = pd.get_dummies(test_data[['Sex']]) \r\n",
        "test_data = test_data.join(temp)\r\n",
        "\r\n",
        "temp = pd.get_dummies(titanic_data[['Pclass']].astype(str)) \r\n",
        "temp.head()\r\n",
        "titanic_data = titanic_data.join(temp)\r\n",
        "\r\n",
        "temp = pd.get_dummies(test_data[['Pclass']].astype(str)) \r\n",
        "test_data = test_data.join(temp)\r\n",
        "\r\n",
        "temp = pd.get_dummies(titanic_data[['Embarked']]) \r\n",
        "titanic_data= titanic_data.join(temp)\r\n",
        "\r\n",
        "temp = pd.get_dummies(test_data[['Embarked']]) \r\n",
        "test_data= test_data.join(temp)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder \r\n",
        "\r\n",
        "le = LabelEncoder() \r\n",
        "le.fit(titanic_data['Ticket']) \r\n",
        "titanic_data['Ticket'] = le.transform(titanic_data['Ticket']) \r\n",
        "\r\n",
        "le = LabelEncoder() \r\n",
        "le.fit(test_data['Ticket']) \r\n",
        "test_data['Ticket'] = le.transform(test_data['Ticket'])\r\n",
        "\r\n",
        "\r\n",
        "le = LabelEncoder() \r\n",
        "le.fit(titanic_data['Cabin']) \r\n",
        "titanic_data['Cabin'] = le.transform(titanic_data['Cabin']) \r\n",
        "\r\n",
        "le = LabelEncoder() \r\n",
        "le.fit(test_data['Cabin']) \r\n",
        "test_data['Cabin'] = le.transform(test_data['Cabin'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Onq_DgSFCnV"
      },
      "source": [
        "titanic_data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esSKw-2FFFj-"
      },
      "source": [
        "titanic_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j06FoDa3FSQE"
      },
      "source": [
        "# Rozpoczynamy skalowanie funkcji. Wykreślamy histogramy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYjzpYPjFj9t"
      },
      "source": [
        "sns.distplot(titanic_data['Age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CAs4TfVFp09"
      },
      "source": [
        "sns.distplot(titanic_data['Fare'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIOHhrXQFuJ1"
      },
      "source": [
        "from sklearn.preprocessing import MaxAbsScaler \r\n",
        "\r\n",
        "\r\n",
        "data_unscaled = titanic_data[['Age','Fare']]\r\n",
        "\r\n",
        "data_unscaled = data_unscaled.append(test_data[['Age','Fare']])\r\n",
        "\r\n",
        "scaler = MaxAbsScaler() \r\n",
        "scaler.fit(data_unscaled) \r\n",
        "data_scaled = scaler.transform(data_unscaled)\r\n",
        "\r\n",
        "titanic_data_scaled = data_scaled[:titanic_data.shape[0]]\r\n",
        "test_data_scaled    = data_scaled[titanic_data.shape[0]+1:]\r\n",
        "\r\n",
        "titanic_data_scaled = pd.DataFrame(titanic_data_scaled, columns = data_unscaled.columns) \r\n",
        "test_data_scaled = pd.DataFrame(test_data_scaled, columns = data_unscaled.columns) \r\n",
        "\r\n",
        "\r\n",
        "print(titanic_data_scaled.shape, test_data_scaled.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFQnM-5qmDKm"
      },
      "source": [
        "# Sprawdźamy, czy dane zostały znormalizowane"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QglqJlk4Fu72"
      },
      "source": [
        "test_data_scaled.info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI-PeVGpFzAe"
      },
      "source": [
        "titanic_data[['Age','Fare']] = titanic_data_scaled[['Age','Fare']]\r\n",
        "test_data[['Age','Fare']] = test_data_scaled[['Age','Fare']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2vHkCv3mU8G"
      },
      "source": [
        "# Sprawdźamy jakie zmiany zostały dokonane."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmLT89aUF05l"
      },
      "source": [
        "sns.distplot(titanic_data['Age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLAuHWu3F2Tt"
      },
      "source": [
        "sns.distplot(titanic_data['Fare'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQuV-tchmlSW"
      },
      "source": [
        "# Rozpoczynamy test zbioru danych. Generujemy testowe zestawy danych.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ncZtHPJGAtO"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AE1FijlJGDU3"
      },
      "source": [
        "selected_x_columns = ['Age','SibSp','Parch', 'Sex_female', 'Sex_male', 'Pclass_1', 'Pclass_2', 'Pclass_3' ]\r\n",
        "train_x = titanic_data[selected_x_columns]\r\n",
        "test_x =  test_data[selected_x_columns]\r\n",
        "\r\n",
        "train_y = titanic_data['Survived']\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w8VLqiVGE04"
      },
      "source": [
        "print(train_x.shape, test_x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYE8HCSDGa4d"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(30, input_dim=train_x.shape[1], activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(60, activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(30, activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(16, activation='relu'))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "...\r\n",
        "\r\n",
        "model.fit(train_x, train_y, epochs=300, batch_size=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP0rp6QZGdb9"
      },
      "source": [
        "test_y = model.predict(test_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Xa9opyGfXX"
      },
      "source": [
        "test_y = np.where(test_y>0.8, 1,0)\r\n",
        "\r\n",
        "test_y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-EALBjZGgxO"
      },
      "source": [
        "result = test_data.join(pd.DataFrame(test_y, columns=['Survived']))\r\n",
        "result = result[['PassengerId', 'Survived']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg98dTqpGiom"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxrpz9Y1m-lO"
      },
      "source": [
        "# Przesyłanie wyników."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MejT8SN0Gk7u"
      },
      "source": [
        "result.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8I23plQnROW"
      },
      "source": [
        "# Wnioski\r\n",
        "\r\n",
        "Wynik jaki został wygnerowany są na poziome 0.8373 z maksymalną różnicą nie przekraczjącą dwóch setnych. W celu poprawy wyników należy rozważyć wiecej możliwych modeli. Otrzymane wyniki są w pełnii zadowalające."
      ]
    }
  ]
}